---
title: "Technical Projects & Research"
description: "A showcase of my key Machine Learning (ML), Generative AI, and Software Engineering projects, demonstrating proficiency from low-level systems to modern deep learning architectures."
date: 2025-11-24
---

## üî¨ Academic Research & Generative AI

---

### üé® Generative AI for Image Inpainting (MEng Thesis)

**Context:** MEng Research Project, Imperial College London

**Description:** This Master's thesis explored novel techniques for **text-conditioned image manipulation** by enhancing the object replacement and inpainting process using advanced segmentation and diffusion models.

* **Core Architectures:** The work involved exploring and benchmarking different **Diffusion Model architectures** to accurately fill masked regions of an image using contextual information.
* **Novel Methodology:** Developed and refined a novel methodology for improving GenAI image inpainting algorithms by integrating secondary AI mask generation.
* **Pipeline & Achievement:** Built a "find and replace" pipeline to segment objects using a text prompt, achieving **state-of-the-art visual coherence** for the inpainting process.

### üß† Masters Thesis (Future Focus)

**Institution:** Queen Mary University of London (Expected 2026)

**Description:** Currently specializing in **Multimodal AI** (Image, Audio, Language models) and Deep Learning Architectures, with a Predicted Classification of **1st (Distinction)**. The future project will focus on applied research within emerging Generative AI domains.

* **Target Area:** Aiming to undertake a project involving state-of-the-art **Vision-Language Models (VLMs)** or complex **Computer Vision** tasks.
* **Core Disciplines:** Deep Learning, Multimodal AI, and advanced Computer Vision architectures.

---

## üõ°Ô∏è Machine Learning & Optimization

---

### üìä High-Impact Fraud Detection Model

**Context:** Personal Project (Kaggle Dataset)

**Description:** Developed and rigorously optimized a financial fraud detection system, focusing on maximizing the capture rate of high-cost fraud cases (minimizing False Negatives) in a severely imbalanced credit card fraud dataset.

* **Model Architecture:** Built and optimized an **XGBoost** classifier, chosen for its speed, interpretability, and robust performance on tabular data.
* **Strategic Optimization:** Optimized the model for the **F-beta score ($\beta=20$)**‚Äîa metric explicitly weighting **Recall** over Precision‚Äîto heavily penalize high-cost false negatives.
* **Metric Achievement:** Achieved an exceptional **Recall of 95.7%** (catching 44 out of 46 fraud cases) by strategically shifting the classification threshold to **0.0035**. This result prioritized **loss prevention** over minimizing false alarms, a necessary trade-off that resulted in a Precision of **4.6%**.

### üó∫Ô∏è Full-Waveform Inversion (FWI) for Geophysical Imaging

**Context:** Kaggle & Yale/UNC-CH ML Competition

**Description:** Engineered a sophisticated machine learning solution for a complex geophysical imaging problem, demonstrating adaptability to large-scale scientific datasets.

* **Architecture & Techniques:** Utilized **deep learning (U-Net)** and signal processing techniques to invert seismic waveform data.
* **Data Handling:** Showcased proficiency in handling non-standard, large-scale scientific datasets.
* **Achievement:** Achieved a highly competitive result in a specialized domain, demonstrating strong problem-solving and technical adaptation skills.

---

## üíª Foundational Systems & Learning

---

### üìù Foundational Deep Learning: GPT-2 Clone

**Description:** Implemented a foundational Generative AI architecture from scratch to gain a deep understanding of core transformer mechanics.

* **Core Implementation:** Built a decoder-only causal language model entirely in **PyTorch**, replicating the key components of the **GPT-2 architecture** (self-attention, residual connections).
* **Data and Tokenization:** Preprocessed the script of *The Matrix* to create the training corpus and utilized **Byte Pair Encoding (BPE)** for efficient tokenization.
* **Objective:** Demonstrated end-to-end knowledge of modern LLM pipelines, from data ingestion and tokenization to forward pass calculations and text generation sampling.

### ü•á Kaggle Classification Competitions

**Description:** Showcase of proficiency in fundamental Deep Learning and ML techniques using widely recognized benchmark challenges.

* **MNIST Digit Recognition:** Achieved **99%+ accuracy** on the MNIST classification benchmark using a custom-built **Convolutional Neural Network (CNN)**, validating a strong grasp of foundational Computer Vision architectures and training stability.
* **Additional Competitions:** Participation in various other challenges (e.g., FWI) demonstrates adaptability across different data types (tabular, image, seismic signal) and modeling goals.
